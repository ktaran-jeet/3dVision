{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMm2GlNkWR/Jy07FC367Dur",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ktaran-jeet/3dVision/blob/DLNotes/Linear.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "vrm5R6LbSBid"
      },
      "outputs": [],
      "source": [
        "##Linear module:\n",
        "import torch\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#In the context of neural networks, a linear layer (also known as a fully connected layer or dense layer) applies a linear transformation to its input. This transformation is defined by the equation: y = x * W^T + b\n",
        "module = nn.Linear(5,3)\n",
        "print(module)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uJv0wHN7Xp5a",
        "outputId": "bfca2bd0-8fc1-4a82-b14c-33e6233c86c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linear(in_features=5, out_features=3, bias=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ip = torch.rand(5)\n",
        "print(ip)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RCmhC4o5X-y7",
        "outputId": "6023501a-a196-4765-f74b-28fd3294102b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.5478, 0.0385, 0.7758, 0.4499, 0.9995])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = module(ip)\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qepH4vWvYEFJ",
        "outputId": "fa2924d9-9ab6-42db-da15-2789afa3682a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-0.3043, -0.3537, -0.3266], grad_fn=<ViewBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(module.weight)\n",
        "print(module.weight.size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "riEk5vYpYHcL",
        "outputId": "134b5da3-6c4b-45fb-fb46-552b77a6d3f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter containing:\n",
            "tensor([[-0.0118,  0.3327, -0.2300, -0.3586, -0.0776],\n",
            "        [ 0.0556,  0.0843, -0.2661, -0.2053, -0.1646],\n",
            "        [-0.3621, -0.2757,  0.0608,  0.0439, -0.3471]], requires_grad=True)\n",
            "torch.Size([3, 5])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(module.bias)\n",
        "print(module.bias.size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BKb9XxdkYiYa",
        "outputId": "bcedee17-e9f2-487e-8c32-aaf217220621"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter containing:\n",
            "tensor([0.1067, 0.0759, 0.1624], requires_grad=True)\n",
            "torch.Size([3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##The primary purpose of using with torch.no_grad(): is to temporarily disable gradient calculations within the code block it encloses.\n",
        "## during inference, evaluation or durring manipulating model params directly.\n",
        "with torch.no_grad():\n",
        "  module.weight[0,0] = 0\n",
        "  module.weight[2,0] = 0\n",
        "  module.bias[0] = 0\n",
        "  print(module.weight)\n",
        "  print(module.bias)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pn4HQBheYqdC",
        "outputId": "852f649c-909d-4c20-955d-c9d00f42a3ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter containing:\n",
            "tensor([[ 0.0000,  0.3327, -0.2300, -0.3586, -0.0776],\n",
            "        [ 0.0556,  0.0843, -0.2661, -0.2053, -0.1646],\n",
            "        [ 0.0000, -0.2757,  0.0608,  0.0439, -0.3471]], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([0.0000, 0.0759, 0.1624], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## A linear module without bias:\n",
        "mod = nn.Linear(2,3,bias=False)\n",
        "print(mod)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2VVXU0L4aX7D",
        "outputId": "5933480b-f651-4405-e2a1-a46bcb105f2a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linear(in_features=2, out_features=3, bias=False)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(mod.weight)\n",
        "print(mod.bias)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8t_r2ea2a2dG",
        "outputId": "75b22f78-0078-42b1-b25d-ffe8a1927949"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter containing:\n",
            "tensor([[-0.4626,  0.2284],\n",
            "        [ 0.0786,  0.1744],\n",
            "        [-0.4646, -0.3355]], requires_grad=True)\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.ones(2)\n",
        "print(x)\n",
        "y = mod(x)\n",
        "print(y)"
      ],
      "metadata": {
        "id": "dO0U2an3Ql1S",
        "outputId": "653cd7fb-60b6-41a1-ed1c-34f338534e19",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1., 1.])\n",
            "tensor([ 3.,  7., 11.], grad_fn=<SqueezeBackward4>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "OqiCeXPqRbwJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wm = torch.arange(1,7).reshape(3,2).float()\n",
        "print(wm.dtype)\n",
        "with torch.no_grad():\n",
        "  mod.weight = nn.Parameter(wm)\n",
        "  print(mod.weight)"
      ],
      "metadata": {
        "id": "F98avpwyQwYx",
        "outputId": "01e93824-3d57-48dc-bbce-47a8d9964b8c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.float32\n",
            "Parameter containing:\n",
            "tensor([[1., 2.],\n",
            "        [3., 4.],\n",
            "        [5., 6.]], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "newy = mod(x)\n",
        "print(newy)"
      ],
      "metadata": {
        "id": "w3WX1altRMVT",
        "outputId": "d16a6d0a-a5e9-4fe5-cbb6-009a66fcf9b6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 3.,  7., 11.], grad_fn=<SqueezeBackward4>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##Activation fucntion: Softmax:\n",
        "import numpy as np\n",
        "#numerical stability. When dealing with exponentials, values can become very large, leading to potential overflow errors. By subtracting the maximum value (np.max(x)) before exponentiation, we shift the values towards zero, reducing the risk of overflow. This ensures the function produces more reliable results, especially when dealing with large input values\n",
        "\n",
        "def softmax(x):\n",
        "  x = x-np.max(x)\n",
        "  return np.exp(x)/np.sum(np.exp(x))\n",
        "\n",
        "logits = np.array([1.0,2.0,3.0])\n",
        "print(softmax(logits))\n",
        "print(np.sum(softmax(logits)))"
      ],
      "metadata": {
        "id": "GNvHzKvBSeoG",
        "outputId": "83f69898-ecd9-4dd4-b2e5-46f4b0c218dd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.09003057 0.24472847 0.66524096]\n",
            "0.9999999999999999\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "logits = torch.tensor([1.0,2.0,3.0])\n",
        "probs = F.softmax(logits, dim=0)\n",
        "print(probs)\n",
        "print(torch.sum(probs))"
      ],
      "metadata": {
        "id": "dPykiCSdamSH",
        "outputId": "17f86811-a9b2-4000-8468-891685d38a53",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.0900, 0.2447, 0.6652])\n",
            "tensor(1.)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xx = torch.Tensor(torch.arange(1,13).reshape(3,4).float())\n",
        "print(xx)\n",
        "p = torch.nn.functional.softmax(xx,dim=0)\n",
        "py = torch.nn.functional.softmax(xx,dim=1)\n",
        "print(p)\n",
        "print(p.sum(dim=0))\n",
        "print('')\n",
        "print(py)\n",
        "print(py.sum(dim=1))"
      ],
      "metadata": {
        "id": "Z1rCWmBlcF_c",
        "outputId": "6ad1f5bf-02b5-4c96-ddfc-59d378b6a42d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 1.,  2.,  3.,  4.],\n",
            "        [ 5.,  6.,  7.,  8.],\n",
            "        [ 9., 10., 11., 12.]])\n",
            "tensor([[3.2932e-04, 3.2932e-04, 3.2932e-04, 3.2932e-04],\n",
            "        [1.7980e-02, 1.7980e-02, 1.7980e-02, 1.7980e-02],\n",
            "        [9.8169e-01, 9.8169e-01, 9.8169e-01, 9.8169e-01]])\n",
            "tensor([1.0000, 1.0000, 1.0000, 1.0000])\n",
            "\n",
            "tensor([[0.0321, 0.0871, 0.2369, 0.6439],\n",
            "        [0.0321, 0.0871, 0.2369, 0.6439],\n",
            "        [0.0321, 0.0871, 0.2369, 0.6439]])\n",
            "tensor([1., 1., 1.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## vanilla neural networks::\n",
        "import torch.nn as nn\n",
        "\n",
        "class simpleNet(nn.Module):\n",
        "\n",
        "  def __init__(self, inputl, hiddenl, outputl):\n",
        "    super(simpleNet, self).__init__()\n",
        "\n",
        "    self.layer1 = nn.Linear(inputl, hiddenl, bias=True)\n",
        "    self.layer2 = nn.Linear(hiddenl, outputl, bias=True)\n",
        "\n",
        "  def forward(self,x):\n",
        "    x = self.layer1(x)\n",
        "    x = torch.relu(x)\n",
        "    x = self.layer2(x)\n",
        "    p = torch.softmax(x, dim=0)\n",
        "    return p\n",
        "\n",
        "snet = simpleNet(2,5,3)\n",
        "print(snet)"
      ],
      "metadata": {
        "id": "zsn9pzS3hHT-",
        "outputId": "9c0747eb-1067-42c7-bb7a-1d95e7fddba1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "simpleNet(\n",
            "  (layer1): Linear(in_features=2, out_features=5, bias=True)\n",
            "  (layer2): Linear(in_features=5, out_features=3, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.Tensor([1,1])\n",
        "print(x)\n",
        "prob = snet.forward(x) ##both are equivalent!\n",
        "prob2 = snet(x)\n",
        "print(prob)\n",
        "print(prob2)"
      ],
      "metadata": {
        "id": "PX5j4vp7laXT",
        "outputId": "2be03300-c695-42f0-f3a0-52f8adad478b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1., 1.])\n",
            "tensor([0.2062, 0.1620, 0.6318], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([0.2062, 0.1620, 0.6318], grad_fn=<SoftmaxBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(snet.layer1.weight)\n",
        "print(snet.layer1.bias)"
      ],
      "metadata": {
        "id": "iz6RnvhGlzhS",
        "outputId": "253f6c1f-ec89-4481-a753-adf7e9cc80b2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter containing:\n",
            "tensor([[ 0.1221,  0.3344],\n",
            "        [-0.3274, -0.4230],\n",
            "        [-0.2041, -0.3286],\n",
            "        [ 0.0626, -0.4214],\n",
            "        [ 0.0604,  0.0039]], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([ 0.6126, -0.0934,  0.6503, -0.5885,  0.1455], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  snet.layer1.weight[0,1]=0\n",
        "  snet.layer1.weight[2,0]=0\n",
        "  print(snet.layer1.weight)\n",
        "\n",
        "nprob = snet(x)\n",
        "print(nprob)\n",
        "## probablities changed with change in weights!"
      ],
      "metadata": {
        "id": "bTSxrMRomz_j",
        "outputId": "0acb960c-685c-4e44-e0ef-0b6427663084",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter containing:\n",
            "tensor([[ 0.1221,  0.0000],\n",
            "        [-0.3274, -0.4230],\n",
            "        [ 0.0000, -0.3286],\n",
            "        [ 0.0626, -0.4214],\n",
            "        [ 0.0604,  0.0039]], requires_grad=True)\n",
            "tensor([0.2306, 0.1982, 0.5711], grad_fn=<SoftmaxBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(snet.layer2.weight)\n",
        "print(snet.layer2.bias)"
      ],
      "metadata": {
        "id": "pEUJiw7umUF4",
        "outputId": "f792d4a4-f284-4484-8023-0c8dcfbfdc17",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter containing:\n",
            "tensor([[-0.2065,  0.2463,  0.0035,  0.1825,  0.2718],\n",
            "        [-0.3504,  0.1920,  0.2101,  0.1474, -0.2457],\n",
            "        [ 0.2867, -0.2425, -0.2312, -0.1056, -0.0475]], requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.2922, -0.2957,  0.3947], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "list_of_param = list(snet.parameters() )\n",
        "print(list_of_param)"
      ],
      "metadata": {
        "id": "hiWVNALamZ6u",
        "outputId": "ed05b2a9-06b9-4d80-af7d-c0552244530e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Parameter containing:\n",
            "tensor([[ 0.1221,  0.3344],\n",
            "        [-0.3274, -0.4230],\n",
            "        [-0.2041, -0.3286],\n",
            "        [ 0.0626, -0.4214],\n",
            "        [ 0.0604,  0.0039]], requires_grad=True), Parameter containing:\n",
            "tensor([ 0.6126, -0.0934,  0.6503, -0.5885,  0.1455], requires_grad=True), Parameter containing:\n",
            "tensor([[-0.2065,  0.2463,  0.0035,  0.1825,  0.2718],\n",
            "        [-0.3504,  0.1920,  0.2101,  0.1474, -0.2457],\n",
            "        [ 0.2867, -0.2425, -0.2312, -0.1056, -0.0475]], requires_grad=True), Parameter containing:\n",
            "tensor([-0.2922, -0.2957,  0.3947], requires_grad=True)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Training nn on mnist dataset:\n",
        "import utils\n",
        "from utils import check_mnist_dataset_exists\n",
        "data_path=check_mnist_dataset_exists()"
      ],
      "metadata": {
        "id": "kE28I07UmttK",
        "outputId": "2b5e8d8e-dc1a-43ae-fa28-448565c42012",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        }
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'utils'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-63-62abf48be274>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m### Training nn on mnist dataset:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcheck_mnist_dataset_exists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdata_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_mnist_dataset_exists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'utils'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xmyg0MNqovdG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}